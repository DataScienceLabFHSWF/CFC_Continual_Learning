{'seed': None, 'notes': None, 'non_verbose': 0, 'disable_log': 0, 'validation': 0, 'ignore_other_metrics': 0, 'debug_mode': 0, 'nowand': 0, 'wandb_entity': 'fneubuerger', 'wandb_project': 'mammoth', 'dataset': 'seq-cifar10', 'model': 'er', 'lr': 0.0001, 'optim_wd': 0.0, 'optim_mom': 0.0, 'optim_nesterov': 0, 'n_epochs': 20, 'batch_size': 32, 'distributed': 'no', 'buffer_size': 500, 'minibatch_size': 32, 'conf_jobnum': '43f56c14-252e-4270-9794-9a8075d11567', 'conf_timestamp': '2023-04-17 09:10:31.723664', 'conf_host': 'DSFHSWF-PowerEdge-R7525', 'wandb_url': 'https://wandb.ai/fneubuerger/mammoth/runs/vqm1uq6t', 'accmean_task1': 86.45, 'accmean_task2': 79.625, 'accmean_task3': 78.23333333333333, 'accmean_task4': 78.1875, 'accmean_task5': 79.83, 'accuracy_1_task1': 86.45, 'accuracy_1_task2': 86.15, 'accuracy_2_task2': 73.1, 'accuracy_1_task3': 84.15, 'accuracy_2_task3': 70.89999999999999, 'accuracy_3_task3': 79.65, 'accuracy_1_task4': 80.55, 'accuracy_2_task4': 69.95, 'accuracy_3_task4': 74.65, 'accuracy_4_task4': 87.6, 'accuracy_1_task5': 85.39999999999999, 'accuracy_2_task5': 68.8, 'accuracy_3_task5': 72.75, 'accuracy_4_task5': 84.6, 'accuracy_5_task5': 87.6, 'forward_transfer': -2.375, 'backward_transfer': -3.8125000000000036, 'forgetting': 3.8125000000000036}
{'seed': None, 'notes': None, 'non_verbose': 0, 'disable_log': 0, 'validation': 0, 'ignore_other_metrics': 0, 'debug_mode': 0, 'nowand': 0, 'wandb_entity': 'fneubuerger', 'wandb_project': 'mammoth', 'dataset': 'seq-cifar10', 'model': 'er', 'lr': 0.0001, 'optim_wd': 0.0, 'optim_mom': 0.0, 'optim_nesterov': 0, 'n_epochs': 50, 'batch_size': 32, 'distributed': 'no', 'buffer_size': 200, 'minibatch_size': 32, 'conf_jobnum': '6269ebc4-bbdc-467e-8c3a-dafa059a961a', 'conf_timestamp': '2023-11-16 09:45:05.229611', 'conf_host': 'DSFHSWF-PowerEdge-R7525', 'wandb_url': 'https://wandb.ai/fneubuerger/mammoth/runs/21imywqe', 'accmean_task1': 91.60000000000001, 'accmean_task2': 81.6, 'accmean_task3': 74.10000000000001, 'accmean_task4': 76.5625, 'accmean_task5': 78.84, 'accuracy_1_task1': 91.60000000000001, 'accuracy_1_task2': 84.15, 'accuracy_2_task2': 79.05, 'accuracy_1_task3': 73.35000000000001, 'accuracy_2_task3': 66.4, 'accuracy_3_task3': 82.55, 'accuracy_1_task4': 73.3, 'accuracy_2_task4': 68.95, 'accuracy_3_task4': 71.35000000000001, 'accuracy_4_task4': 92.65, 'accuracy_1_task5': 79.25, 'accuracy_2_task5': 69.15, 'accuracy_3_task5': 69.25, 'accuracy_4_task5': 86.55000000000001, 'accuracy_5_task5': 90.0, 'forward_transfer': 2.6125000000000043, 'backward_transfer': -10.412499999999998, 'forgetting': 10.412499999999998}
