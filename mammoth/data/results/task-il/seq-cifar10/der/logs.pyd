{'seed': None, 'notes': None, 'non_verbose': 0, 'disable_log': 0, 'validation': 0, 'ignore_other_metrics': 0, 'debug_mode': 0, 'nowand': 0, 'wandb_entity': 'fneubuerger', 'wandb_project': 'mammoth', 'dataset': 'seq-cifar10', 'model': 'der', 'lr': 0.0001, 'optim_wd': 0.0, 'optim_mom': 0.0, 'optim_nesterov': 0, 'n_epochs': 20, 'batch_size': 32, 'distributed': 'no', 'buffer_size': 10, 'minibatch_size': 32, 'alpha': 0.001, 'conf_jobnum': '5f20d83b-ec82-4399-ab78-0fe0b5597052', 'conf_timestamp': '2023-04-03 10:42:18.156490', 'conf_host': 'DSFHSWF-PowerEdge-R7525', 'wandb_url': 'https://wandb.ai/fneubuerger/mammoth/runs/azy1lux1', 'accmean_task1': 85.45, 'accmean_task2': 74.19999999999999, 'accmean_task3': 69.58333333333333, 'accmean_task4': 67.3375, 'accmean_task5': 72.0, 'accuracy_1_task1': 85.45, 'accuracy_1_task2': 73.25, 'accuracy_2_task2': 75.14999999999999, 'accuracy_1_task3': 60.0, 'accuracy_2_task3': 66.05, 'accuracy_3_task3': 82.69999999999999, 'accuracy_1_task4': 58.95, 'accuracy_2_task4': 52.849999999999994, 'accuracy_3_task4': 67.80000000000001, 'accuracy_4_task4': 89.75, 'accuracy_1_task5': 76.9, 'accuracy_2_task5': 55.35, 'accuracy_3_task5': 58.3, 'accuracy_4_task5': 79.75, 'accuracy_5_task5': 89.7, 'forward_transfer': 3.612499999999997, 'backward_transfer': -15.687499999999995, 'forgetting': 15.687499999999995}
{'seed': None, 'notes': None, 'non_verbose': 0, 'disable_log': 0, 'validation': 0, 'ignore_other_metrics': 0, 'debug_mode': 1, 'nowand': 1, 'wandb_entity': 'fneubuerger', 'wandb_project': 'mammoth', 'dataset': 'seq-cifar10', 'model': 'der', 'lr': 0.0001, 'optim_wd': 0.0, 'optim_mom': 0.0, 'optim_nesterov': 0, 'n_epochs': 20, 'batch_size': 32, 'distributed': 'no', 'buffer_size': 10, 'minibatch_size': 32, 'alpha': 0.001, 'conf_jobnum': '15313d9f-6696-4bde-942c-a1187db8ac2e', 'conf_timestamp': '2023-04-03 11:44:08.447903', 'conf_host': 'DSFHSWF-PowerEdge-R7525', 'accmean_task1': 49.9, 'accmean_task2': 50.5, 'accmean_task3': 55.54999999999999, 'accmean_task4': 56.662499999999994, 'accmean_task5': 56.32000000000001, 'accuracy_1_task1': 49.9, 'accuracy_1_task2': 50.9, 'accuracy_2_task2': 50.1, 'accuracy_1_task3': 51.1, 'accuracy_2_task3': 50.4, 'accuracy_3_task3': 65.14999999999999, 'accuracy_1_task4': 51.849999999999994, 'accuracy_2_task4': 50.449999999999996, 'accuracy_3_task4': 64.9, 'accuracy_4_task4': 59.45, 'accuracy_1_task5': 52.15, 'accuracy_2_task5': 49.95, 'accuracy_3_task5': 63.7, 'accuracy_4_task5': 54.85, 'accuracy_5_task5': 60.95, 'forward_transfer': 0.7249999999999996, 'backward_transfer': -0.9874999999999972, 'forgetting': 1.6374999999999957}
{'seed': None, 'notes': None, 'non_verbose': 0, 'disable_log': 0, 'validation': 0, 'ignore_other_metrics': 0, 'debug_mode': 0, 'nowand': 0, 'wandb_entity': 'fneubuerger', 'wandb_project': 'mammoth', 'dataset': 'seq-cifar10', 'model': 'der', 'lr': 0.0001, 'optim_wd': 0.0, 'optim_mom': 0.0, 'optim_nesterov': 0, 'n_epochs': 20, 'batch_size': 32, 'distributed': 'no', 'buffer_size': 10, 'minibatch_size': 32, 'alpha': 0.1, 'conf_jobnum': 'ee00571e-95c5-45f2-af2b-16106119f1f3', 'conf_timestamp': '2023-04-03 11:47:00.644169', 'conf_host': 'DSFHSWF-PowerEdge-R7525', 'wandb_url': 'https://wandb.ai/fneubuerger/mammoth/runs/om8mwvvm', 'accmean_task1': 87.9, 'accmean_task2': 71.875, 'accmean_task3': 70.5, 'accmean_task4': 69.0875, 'accmean_task5': 68.96000000000001, 'accuracy_1_task1': 87.9, 'accuracy_1_task2': 68.35, 'accuracy_2_task2': 75.4, 'accuracy_1_task3': 62.35000000000001, 'accuracy_2_task3': 66.75, 'accuracy_3_task3': 82.39999999999999, 'accuracy_1_task4': 58.45, 'accuracy_2_task4': 59.95, 'accuracy_3_task4': 64.8, 'accuracy_4_task4': 93.15, 'accuracy_1_task5': 63.2, 'accuracy_2_task5': 57.25, 'accuracy_3_task5': 55.7, 'accuracy_4_task5': 80.45, 'accuracy_5_task5': 88.2, 'forward_transfer': 0.8125, 'backward_transfer': -20.5625, 'forgetting': 20.5625}
{'seed': None, 'notes': None, 'non_verbose': 0, 'disable_log': 0, 'validation': 0, 'ignore_other_metrics': 0, 'debug_mode': 0, 'nowand': 0, 'wandb_entity': 'fneubuerger', 'wandb_project': 'mammoth', 'dataset': 'seq-cifar10', 'model': 'der', 'lr': 0.0001, 'optim_wd': 0.0, 'optim_mom': 0.0, 'optim_nesterov': 0, 'n_epochs': 20, 'batch_size': 32, 'distributed': 'no', 'buffer_size': 10, 'minibatch_size': 32, 'alpha': 0.1, 'conf_jobnum': 'e5e4e44c-8399-4617-bc56-76be985a4a4e', 'conf_timestamp': '2023-11-15 12:54:30.557924', 'conf_host': 'DSFHSWF-PowerEdge-R7525', 'wandb_url': 'https://wandb.ai/fneubuerger/mammoth/runs/2be7z9ko', 'accmean_task1': 88.2, 'accmean_task2': 76.89999999999999, 'accmean_task3': 73.06666666666668, 'accmean_task4': 70.5, 'accmean_task5': 71.14000000000001, 'accuracy_1_task1': 88.2, 'accuracy_1_task2': 78.64999999999999, 'accuracy_2_task2': 75.14999999999999, 'accuracy_1_task3': 69.25, 'accuracy_2_task3': 67.10000000000001, 'accuracy_3_task3': 82.85, 'accuracy_1_task4': 67.10000000000001, 'accuracy_2_task4': 58.3, 'accuracy_3_task4': 65.45, 'accuracy_4_task4': 91.14999999999999, 'accuracy_1_task5': 76.05, 'accuracy_2_task5': 54.949999999999996, 'accuracy_3_task5': 62.150000000000006, 'accuracy_4_task5': 75.64999999999999, 'accuracy_5_task5': 86.9, 'forward_transfer': -3.9999999999999982, 'backward_transfer': -17.137499999999996, 'forgetting': 17.137499999999996}
{'seed': None, 'notes': None, 'non_verbose': 0, 'disable_log': 0, 'validation': 0, 'ignore_other_metrics': 0, 'debug_mode': 0, 'nowand': 0, 'wandb_entity': 'fneubuerger', 'wandb_project': 'mammoth', 'dataset': 'seq-cifar10', 'model': 'der', 'lr': 0.0001, 'optim_wd': 0.0, 'optim_mom': 0.0, 'optim_nesterov': 0, 'n_epochs': 50, 'batch_size': 32, 'distributed': 'no', 'buffer_size': 200, 'minibatch_size': 32, 'alpha': 0.1, 'conf_jobnum': '0d2fe1ff-67c6-4e51-8930-e41b7b468a52', 'conf_timestamp': '2023-11-16 09:43:28.845924', 'conf_host': 'DSFHSWF-PowerEdge-R7525', 'wandb_url': 'https://wandb.ai/fneubuerger/mammoth/runs/3bllx4ox', 'accmean_task1': 92.0, 'accmean_task2': 82.44999999999999, 'accmean_task3': 75.96666666666665, 'accmean_task4': 77.175, 'accmean_task5': 81.33, 'accuracy_1_task1': 92.0, 'accuracy_1_task2': 83.5, 'accuracy_2_task2': 81.39999999999999, 'accuracy_1_task3': 83.1, 'accuracy_2_task3': 62.849999999999994, 'accuracy_3_task3': 81.95, 'accuracy_1_task4': 70.5, 'accuracy_2_task4': 68.95, 'accuracy_3_task4': 74.2, 'accuracy_4_task4': 95.05, 'accuracy_1_task5': 85.15, 'accuracy_2_task5': 68.0, 'accuracy_3_task5': 76.0, 'accuracy_4_task5': 83.65, 'accuracy_5_task5': 93.85, 'forward_transfer': -0.7125000000000021, 'backward_transfer': -9.399999999999995, 'forgetting': 9.399999999999995}
